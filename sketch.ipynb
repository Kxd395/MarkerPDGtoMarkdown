{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz as pymupdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(57.024505615234375,\n",
       "  239.432861328125,\n",
       "  61.092193603515625,\n",
       "  249.75694274902344,\n",
       "  'I\\n',\n",
       "  0,\n",
       "  0),\n",
       " (94.6344985961914,\n",
       "  323.6453552246094,\n",
       "  229.39434814453125,\n",
       "  335.5650939941406,\n",
       "  '1\\n1\\n2\\n4\\n',\n",
       "  1,\n",
       "  0),\n",
       " (498.6033630371094,\n",
       "  225.67111206054688,\n",
       "  504.3451232910156,\n",
       "  237.20504760742188,\n",
       "  '1\\n',\n",
       "  2,\n",
       "  0),\n",
       " (470.87774658203125,\n",
       "  210.9396514892578,\n",
       "  483.7017517089844,\n",
       "  213.182373046875,\n",
       "  'density map D\\n',\n",
       "  3,\n",
       "  0),\n",
       " (472.27081298828125,\n",
       "  213.3055877685547,\n",
       "  482.31011962890625,\n",
       "  215.54830932617188,\n",
       "  '(1 channel)\\n',\n",
       "  4,\n",
       "  0),\n",
       " (401.3011779785156,\n",
       "  225.26437377929688,\n",
       "  457.8829650878906,\n",
       "  237.18397521972656,\n",
       "  '8\\n16\\n',\n",
       "  5,\n",
       "  0),\n",
       " (92.5278549194336,\n",
       "  273.5715637207031,\n",
       "  228.43081665039062,\n",
       "  286.4736633300781,\n",
       "  '2\\n2\\n4\\n8\\n',\n",
       "  6,\n",
       "  0),\n",
       " (92.5279312133789,\n",
       "  227.07652282714844,\n",
       "  231.79148864746094,\n",
       "  240.0831298828125,\n",
       "  '4\\n4\\n8\\n16\\n',\n",
       "  7,\n",
       "  0),\n",
       " (93.69222259521484,\n",
       "  179.57638549804688,\n",
       "  227.82644653320312,\n",
       "  191.7633819580078,\n",
       "  '2\\n2\\n4\\n8\\n',\n",
       "  8,\n",
       "  0),\n",
       " (92.52808380126953,\n",
       "  128.15028381347656,\n",
       "  230.31887817382812,\n",
       "  141.3268585205078,\n",
       "  '16\\n4\\n4\\n8\\n',\n",
       "  9,\n",
       "  0),\n",
       " (315.1212158203125,\n",
       "  224.61737060546875,\n",
       "  363.3332824707031,\n",
       "  236.15130615234375,\n",
       "  '2\\n4\\n',\n",
       "  10,\n",
       "  0),\n",
       " (513.1563110351562,\n",
       "  239.4329833984375,\n",
       "  521.2091064453125,\n",
       "  249.75706481933594,\n",
       "  'D\\n',\n",
       "  11,\n",
       "  0),\n",
       " (146.912109375,\n",
       "  77.19293212890625,\n",
       "  185.34866333007812,\n",
       "  88.72686767578125,\n",
       "  'columns\\n',\n",
       "  12,\n",
       "  0),\n",
       " (359.7220764160156,\n",
       "  180.22938537597656,\n",
       "  409.6390686035156,\n",
       "  191.76332092285156,\n",
       "  'aggregator\\n',\n",
       "  13,\n",
       "  0),\n",
       " (51.450401306152344,\n",
       "  137.42584228515625,\n",
       "  64.29065704345703,\n",
       "  279.4776611328125,\n",
       "  '5x5\\n3x3\\n',\n",
       "  14,\n",
       "  0),\n",
       " (377.42742919921875,\n",
       "  158.57862854003906,\n",
       "  509.23223876953125,\n",
       "  170.65647888183594,\n",
       "  '3x3\\n1x1\\n',\n",
       "  15,\n",
       "  0),\n",
       " (468.4222106933594,\n",
       "  268.9035339355469,\n",
       "  478.8839416503906,\n",
       "  282.6689758300781,\n",
       "  '∑\\n',\n",
       "  16,\n",
       "  0),\n",
       " (463.05902099609375,\n",
       "  284.959228515625,\n",
       "  487.6647644042969,\n",
       "  294.400390625,\n",
       "  'x ∈ D\\n',\n",
       "  17,\n",
       "  0),\n",
       " (484.0418395996094,\n",
       "  269.6749267578125,\n",
       "  530.2137451171875,\n",
       "  281.4781799316406,\n",
       "  'x = count\\n',\n",
       "  18,\n",
       "  0),\n",
       " (50.11199951171875,\n",
       "  350.7620544433594,\n",
       "  545.1111450195312,\n",
       "  416.3605041503906,\n",
       "  'Figure 1. Fully convolutional architecture diagram (not to scale). Arrows show separate columns that all take the same input. At the end\\nof the columns, the feature maps are merged (concatenated) together and passed to another series of dilated convolutions: the aggregator,\\nwhich can aggregate the multiscale information collected by the columns [25]. The input image is I with C channels. The output single\\nchannel density map is D, and integrating over this map (summing the pixels) results in the ﬁnal count. Initial ﬁlter sizes are labeled with\\nbrackets or lines. Convolution operations are shown as ﬂat rectangles, feature maps are shown as prisms. The number below each ﬁlter\\nrepresents the dilation rate (1 means no dilation).\\n',\n",
       "  19,\n",
       "  0),\n",
       " (50.11199951171875,\n",
       "  436.4645080566406,\n",
       "  286.3651428222656,\n",
       "  713.7993774414062,\n",
       "  'our paper follow this method of producing a density map\\nvia regression. This is particularly advantageous because a\\nsufﬁciently accurate regressor can also locate the objects in\\nthe image via this method. However, the Lempitsky paper\\nignores the issue of perspective scaling and other scaling\\nissues. The work of [27] introduces CNNs (convolutional\\nneural networks) for the purposes of crowd counting, but\\nperforms regression on similarly scaled image patches.\\nThese issues are addressed by the work of [18]. Rubio\\net al. show that a fully convolutional neural network can be\\nused to produce a supervised regressor that produces den-\\nsity maps as in [15]. They further demonstrate a method\\ndubbed HydraCNN which essentially combines multiple\\nconvolutional networks that take in differently scaled im-\\nage patches in order to incorporate multiscale, global in-\\nformation from the image. The premise of this method is\\nthat a single regressor will fail to accurately represent the\\ndifference in values of the features of an image caused by\\nperspective shifts (scaling effects) [18].\\nHowever, the architectures of both [18] and [27] are not\\nfully convolutional due to requiring multiple image patches\\nand, as discussed in [25], the experiments of [11, 17] and\\n[9, 12, 16] leave it unclear as to whether rescaling patches\\n',\n",
       "  20,\n",
       "  0),\n",
       " (308.86199951171875,\n",
       "  436.4654235839844,\n",
       "  545.1151123046875,\n",
       "  713.7992553710938,\n",
       "  'of the image is truly necessary in order to solve dense pre-\\ndiction problems via convolutional neural networks. More-\\nover, these approaches seem to saturate in performance at\\nthree columns, which means the network is extracting in-\\nformation from fewer scales. The work of [25] proposes\\nthe use of dilated convolutions as a simpler alternative that\\ndoes not require sampling of rescaled image patches to pro-\\nvide global, scale-aware information to the network. A fully\\nconvolutional approach to multiscale counting has been pro-\\nposed by [28], in which a multicolumn convolutional net-\\nwork gathers features of different scales by using convolu-\\ntions of increasing kernel sizes from column to column in-\\nstead of scaling image patches. Further, DeepLab has used\\ndilated convolutions in multiple columns to extract scale\\ninformation for segmentation [8]. We build on these ap-\\nproaches with our aggregator module as described in Sec-\\ntion 3.1, which should allow for extracting information from\\nmore scales.\\nIt should be noted that other methods of counting exist,\\nincluding training a network to recognize deep object fea-\\ntures via only providing the counts of the objects of interest\\nin an image [21] and using CNNs (convolutional neural net-\\nworks) along with boosting in order to improve the results\\n',\n",
       "  21,\n",
       "  0)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = pymupdf.open(\"1804.07821.pdf\", filetype=\"pdf\")\n",
    "\n",
    "pnum = 1\n",
    "page = doc[pnum]\n",
    "# doc.get_page_images(2)\n",
    "page.get_text_blocks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# doc.extract_image(103)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "marker_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
